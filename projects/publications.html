<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Owais Mujtaba Khanday - Publications</title>
<link href="https://cdn.jsdelivr.net/npm/tailwindcss@3.3.3/dist/tailwind.min.css" rel="stylesheet">
<style>
  .pub-card:hover { transform: translateY(-5px); box-shadow: 0 10px 20px rgba(0,0,0,0.1); }
</style>
</head>
<body class="bg-gray-50 text-gray-800">

<header class="bg-blue-900 text-white p-6 text-center">
  <h1 class="text-3xl font-bold">Owais Mujtaba Khanday - Publications</h1>
</header>

<main class="max-w-4xl mx-auto mt-10 px-4 space-y-6">

  <!-- Publication Card Template -->
  <div class="pub-card bg-white p-6 rounded-xl shadow-md transition duration-300">
    <h2 class="text-xl font-semibold text-blue-800">Effect of Filter Sizes on Image Classification in CNN</h2>
    <p class="text-gray-700 mt-2">Demonstrates smaller CNN filters (3×3) improve accuracy on CIFAR10 and Fashion-MNIST (up to 93.68%).</p>
    <p class="mt-2 text-gray-500"><strong>Journal:</strong> IJ-AI, 2021</p>
    <div class="mt-2 space-x-3">
      <a href="https://doi.org/10.11591/ijai.v10.i4.pp872-878" class="text-blue-600 hover:underline" target="_blank">DOI</a>
    </div>
  </div>

  <div class="pub-card bg-white p-6 rounded-xl shadow-md transition duration-300">
    <h2 class="text-xl font-semibold text-blue-800">Decoding the Mind: Neural Differences and Semantic Representation in Perception and Imagination Across Modalities</h2>
    <p class="text-gray-700 mt-2">Analyzes EEG data for perception vs. imagined speech tasks; CNN achieved 77.89% accuracy.</p>
    <p class="mt-2 text-gray-500"><strong>Conference:</strong> IberSPEECH 2024</p>
    <div class="mt-2 space-x-3">
      <a href="https://doi.org/10.21437/IberSPEECH.2024-26" class="text-blue-600 hover:underline" target="_blank">DOI</a>
      <a href="https://hdl.handle.net/10481/96820" class="text-blue-600 hover:underline" target="_blank">PDF</a>
    </div>
  </div>

  <div class="pub-card bg-white p-6 rounded-xl shadow-md transition duration-300">
    <h2 class="text-xl font-semibold text-blue-800">NeuroIncept Decoder for High-Fidelity Speech Reconstruction from Neural Activity</h2>
    <p class="text-gray-700 mt-2">Introduces NeuroIncept, combining Inception modules + GRUs to reconstruct speech from invasive EEG with correlations of 0.83–0.94.</p>
    <p class="mt-2 text-gray-500"><strong>Conference:</strong> ICASSP 2025</p>
    <div class="mt-2 space-x-3">
      <a href="https://doi.org/10.1109/ICASSP49660.2025.10888547" class="text-blue-600 hover:underline" target="_blank">DOI</a>
    </div>
  </div>

  <div class="pub-card bg-white p-6 rounded-xl shadow-md transition duration-300">
    <h2 class="text-xl font-semibold text-blue-800">Recreating Neural Activity During Speech Production with Language and Speech Model Embeddings</h2>
    <p class="text-gray-700 mt-2">Maps language and speech model embeddings to high-gamma neural activity; reconstruction achieves 0.79–0.99 correlation across participants.</p>
    <p class="mt-2 text-gray-500"><strong>Status:</strong> Preprint / Submitted</p>
  </div>

</main>

<footer class="bg-gray-100 text-center text-gray-600 py-6 mt-10">
  &copy; 2025 Owais Mujtaba Khanday. All rights reserved.
</footer>

</body>
</html>
